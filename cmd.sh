# MMLU
HF_DATASETS_CACHE=/gemini-3/space/thu/hehaowei/huggingface_cache lm_eval --model hf     --model_args pretrained=/gemini-3/space/thu/hehaowei/LLaMA-Factory/saves/TeleChat-2B-A05B-exp16-finewebedu100bt/checkpoint-19000/,trust_remote_code=True,dtype="bfloat16"     --tasks mmlu      --device cuda:0     --batch_size 8  --num_fewshot 5  --cache_requests true

# Hellaswag
HF_DATASETS_CACHE=/gemini-3/space/thu/hehaowei/huggingface_cache lm_eval --model hf     --model_args pretrained=/gemini-3/space/thu/hehaowei/LLaMA-Factory/saves/TeleChat-2B-A05B-exp16-finewebedu100bt/checkpoint-19000/,trust_remote_code=True,dtype="bfloat16"     --tasks hellaswag      --device cuda:0     --batch_size 8  --num_fewshot 0


HF_ENDPOINT=https://hf-mirror.com HF_ALLOW_CODE_EVAL=1 HF_DATASETS_CACHE=/gemini-3/space/thu/hehaowei/huggingface_cache lm_eval --model hf     --model_args pretrained=/gemini-3/space/thu/hehaowei/LLaMA-Factory/saves/TeleChat-2B-A05B-exp2/,trust_remote_code=True,dtype="bfloat16",max_length=8192     --tasks super-glue-lm-eval-v1      --device cuda:0     --batch_size 1
HF_ENDPOINT=https://hf-mirror.com HF_ALLOW_CODE_EVAL=1 HF_DATASETS_CACHE=/gemini-3/space/thu/hehaowei/huggingface_cache lm_eval --model hf     --model_args pretrained=/gemini-3/space/thu/hehaowei/LLaMA-Factory/saves/TeleChat-2B-A05B-exp4/,trust_remote_code=True,dtype="bfloat16",max_length=8192     --tasks super-glue-lm-eval-v1      --device cuda:0     --batch_size 1
HF_ENDPOINT=https://hf-mirror.com HF_ALLOW_CODE_EVAL=1 HF_DATASETS_CACHE=/gemini-3/space/thu/hehaowei/huggingface_cache lm_eval --model hf     --model_args pretrained=/gemini-3/space/thu/hehaowei/LLaMA-Factory/saves/TeleChat-2B-A05B-exp8/,trust_remote_code=True,dtype="bfloat16",max_length=8192     --tasks super-glue-lm-eval-v1      --device cuda:0     --batch_size 1
HF_ENDPOINT=https://hf-mirror.com HF_ALLOW_CODE_EVAL=1 HF_DATASETS_CACHE=/gemini-3/space/thu/hehaowei/huggingface_cache lm_eval --model hf     --model_args pretrained=/gemini-3/space/thu/hehaowei/LLaMA-Factory/saves/TeleChat-2B-A05B-exp16/,trust_remote_code=True,dtype="bfloat16",max_length=8192     --tasks super-glue-lm-eval-v1      --device cuda:0     --batch_size 1

HF_ENDPOINT=https://hf-mirror.com HF_ALLOW_CODE_EVAL=1 HF_DATASETS_CACHE=/gemini-3/space/thu/hehaowei/huggingface_cache lm_eval --model hf     --model_args pretrained=/gemini-3/space/thu/hehaowei/LLaMA-Factory/saves/TeleChat-2B-A05B-hwmoe-param2-act2/,trust_remote_code=True,dtype="bfloat16",max_length=8192     --tasks super-glue-lm-eval-v1      --device cuda:0     --batch_size 1
HF_ENDPOINT=https://hf-mirror.com HF_ALLOW_CODE_EVAL=1 HF_DATASETS_CACHE=/gemini-3/space/thu/hehaowei/huggingface_cache lm_eval --model hf     --model_args pretrained=/gemini-3/space/thu/hehaowei/LLaMA-Factory/saves/TeleChat-2B-A05B-hwmoe-param2-act4/,trust_remote_code=True,dtype="bfloat16",max_length=8192     --tasks super-glue-lm-eval-v1      --device cuda:0     --batch_size 1
HF_ENDPOINT=https://hf-mirror.com HF_ALLOW_CODE_EVAL=1 HF_DATASETS_CACHE=/gemini-3/space/thu/hehaowei/huggingface_cache lm_eval --model hf     --model_args pretrained=/gemini-3/space/thu/hehaowei/LLaMA-Factory/saves/TeleChat-2B-A05B-hwmoe-param2-act8/,trust_remote_code=True,dtype="bfloat16",max_length=8192     --tasks super-glue-lm-eval-v1      --device cuda:0     --batch_size 1
HF_ENDPOINT=https://hf-mirror.com HF_ALLOW_CODE_EVAL=1 HF_DATASETS_CACHE=/gemini-3/space/thu/hehaowei/huggingface_cache lm_eval --model hf     --model_args pretrained=/gemini-3/space/thu/hehaowei/LLaMA-Factory/saves/TeleChat-2B-A05B-hwmoe-param2/,trust_remote_code=True,dtype="bfloat16",max_length=8192     --tasks super-glue-lm-eval-v1      --device cuda:0     --batch_size 1

HF_ENDPOINT=https://hf-mirror.com HF_ALLOW_CODE_EVAL=1 HF_DATASETS_CACHE=/gemini-3/space/thu/hehaowei/huggingface_cache lm_eval --model hf     --model_args pretrained=/gemini-3/space/thu/hehaowei/LLaMA-Factory/saves/Qwen3-1p5B-A0p6B-HWMoE-2exp-finewebedu100bt/,trust_remote_code=True,dtype="bfloat16"     --tasks super-glue-lm-eval-v1      --device cuda:0     --batch_size 1
HF_ENDPOINT=https://hf-mirror.com HF_ALLOW_CODE_EVAL=1 HF_DATASETS_CACHE=/gemini-3/space/thu/hehaowei/huggingface_cache lm_eval --model hf     --model_args pretrained=/gemini-3/space/thu/hehaowei/LLaMA-Factory/saves/Qwen3-1p5B-A0p6B-HWMoE-4exp-finewebedu100bt/,trust_remote_code=True,dtype="bfloat16"     --tasks super-glue-lm-eval-v1      --device cuda:0     --batch_size 1
HF_ENDPOINT=https://hf-mirror.com HF_ALLOW_CODE_EVAL=1 HF_DATASETS_CACHE=/gemini-3/space/thu/hehaowei/huggingface_cache lm_eval --model hf     --model_args pretrained=/gemini-3/space/thu/hehaowei/LLaMA-Factory/saves/Qwen3-1p5B-A0p6B-HWMoE-8exp-finewebedu100bt/,trust_remote_code=True,dtype="bfloat16"     --tasks super-glue-lm-eval-v1      --device cuda:0     --batch_size 1
HF_ENDPOINT=https://hf-mirror.com HF_ALLOW_CODE_EVAL=1 HF_DATASETS_CACHE=/gemini-3/space/thu/hehaowei/huggingface_cache lm_eval --model hf     --model_args pretrained=/gemini-3/space/thu/hehaowei/LLaMA-Factory/saves/Qwen3-1p5B-A0p6B-HWMoE-16exp-finewebedu100bt/,trust_remote_code=True,dtype="bfloat16"     --tasks super-glue-lm-eval-v1      --device cuda:0     --batch_size 1



HF_ENDPOINT=https://hf-mirror.com HF_ALLOW_CODE_EVAL=1 HF_DATASETS_CACHE=/gemini-3/space/thu/hehaowei/huggingface_cache lm_eval --model hf     --model_args pretrained=/gemini-3/space/thu/hehaowei/LLaMA-Factory/saves/Qwen3-1p5B-A0p6B-HWMoE-hwmoe-finewebedu100bt-continue-act2/,trust_remote_code=True,dtype="bfloat16"     --tasks super-glue-lm-eval-v1      --device cuda:0     --batch_size 1
HF_ENDPOINT=https://hf-mirror.com HF_ALLOW_CODE_EVAL=1 HF_DATASETS_CACHE=/gemini-3/space/thu/hehaowei/huggingface_cache lm_eval --model hf     --model_args pretrained=/gemini-3/space/thu/hehaowei/LLaMA-Factory/saves/Qwen3-1p5B-A0p6B-HWMoE-hwmoe-finewebedu100bt-continue-act4/,trust_remote_code=True,dtype="bfloat16"     --tasks super-glue-lm-eval-v1      --device cuda:0     --batch_size 1
HF_ENDPOINT=https://hf-mirror.com HF_ALLOW_CODE_EVAL=1 HF_DATASETS_CACHE=/gemini-3/space/thu/hehaowei/huggingface_cache lm_eval --model hf     --model_args pretrained=/gemini-3/space/thu/hehaowei/LLaMA-Factory/saves/Qwen3-1p5B-A0p6B-HWMoE-hwmoe-finewebedu100bt-continue-act8/,trust_remote_code=True,dtype="bfloat16"     --tasks super-glue-lm-eval-v1      --device cuda:0     --batch_size 1
HF_ENDPOINT=https://hf-mirror.com HF_ALLOW_CODE_EVAL=1 HF_DATASETS_CACHE=/gemini-3/space/thu/hehaowei/huggingface_cache lm_eval --model hf     --model_args pretrained=/gemini-3/space/thu/hehaowei/LLaMA-Factory/saves/Qwen3-1p5B-A0p6B-HWMoE-hwmoe-finewebedu100bt-continue/,trust_remote_code=True,dtype="bfloat16"     --tasks super-glue-lm-eval-v1      --device cuda:0     --batch_size 1



HF_ENDPOINT=https://hf-mirror.com HF_ALLOW_CODE_EVAL=1 HF_DATASETS_CACHE=/gemini-3/space/thu/hehaowei/huggingface_cache lm_eval --model hf     --model_args pretrained=/gemini-3/space/thu/hehaowei/LLaMA-Factory/saves/TeleChat-2B-A05B-exp2/,trust_remote_code=True,dtype="bfloat16",max_length=8192     --tasks pile_10k      --device cuda:0     --batch_size 1
HF_ENDPOINT=https://hf-mirror.com HF_ALLOW_CODE_EVAL=1 HF_DATASETS_CACHE=/gemini-3/space/thu/hehaowei/huggingface_cache lm_eval --model hf     --model_args pretrained=/gemini-3/space/thu/hehaowei/LLaMA-Factory/saves/TeleChat-2B-A05B-exp2/,trust_remote_code=True,dtype="bfloat16",max_length=8192     --tasks bbq      --device cuda:0     --batch_size 1
HF_ENDPOINT=https://hf-mirror.com HF_ALLOW_CODE_EVAL=1 HF_DATASETS_CACHE=/gemini-3/space/thu/hehaowei/huggingface_cache lm_eval --model hf     --model_args pretrained=/gemini-3/space/thu/hehaowei/LLaMA-Factory/saves/TeleChat-2B-A05B-exp2/,trust_remote_code=True,dtype="bfloat16",max_length=8192     --tasks agieval      --device cuda:0     --batch_size 1
HF_ENDPOINT=https://hf-mirror.com HF_ALLOW_CODE_EVAL=1 HF_DATASETS_CACHE=/gemini-3/space/thu/hehaowei/huggingface_cache lm_eval --model hf     --model_args pretrained=/gemini-3/space/thu/hehaowei/LLaMA-Factory/saves/TeleChat-2B-A05B-exp2/,trust_remote_code=True,dtype="bfloat16",max_length=8192     --tasks super-glue-lm-eval-v1      --device cuda:0     --batch_size 1



# LAMBADA

